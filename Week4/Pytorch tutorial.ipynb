{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tutorials\n",
    "\n",
    "Tutotial ngắn về pytorch\n",
    "\n",
    "Author: imthanhlv@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu\n",
    "\n",
    "Trong notebook này các bạn sẽ được làm quen với `Pytorch` và xây dựng mô hình seq2seq.\n",
    "\n",
    "`Pytorch` là một ML framework phổ biến trong giới nghiên cứu về ML, DL vì tính linh hoạt và ổn định của API, độ chi tiết của document & ecosystem xung quanh pytorch. \n",
    "\n",
    "Trong tutorial này chúng ta sẽ bắt đầu từ đơn vị nhỏ nhất của pytorch là `Tensor`, sau đó xây dựng một mô hình neural net và thực tập với seq2seq\n",
    "\n",
    "Để cài đặt trên máy, bạn có thể làm theo hướng dẫn [sau](https://pytorch.org/get-started/locally/). Trên colab đã có sẵn thư viện này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor & các phép tính"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensor` là đơn vị nhỏ nhất trong `Pytorch`, là một ma trận nhiều chiều. Hầu hết các phép tính trên `Tensor` giống với `numpy`(shape, reshape, ones, zeros, indexing...) & broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "tensor = torch.tensor(data)\n",
    "print(f\"{tensor}\\nType: {tensor.dtype}\\nShape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhưng khác ở một số hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.dot(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bên cạnh đó pytorch tensor còn có một số method khác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các phép tính `inplace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`device`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd được đi kèm trong pytorch (giống với các framework ML khác). Chúng ta chỉ cần khai báo chiều forward, pytorch sẽ tự biết cách tính gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([6.], requires_grad=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x ** 3 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad # dy/dx = 3*x^2 = 3 * 36 = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu hỏi: Tại sao ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([5., 2.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a * 2 + 5\n",
    "c = b * 3\n",
    "d = c.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.grad_fn.next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Xây dựng neural networks\n",
    "\n",
    "Là một framework deep learning, `Pytorch` đi kèm sẵn các class trong `torch.nn` để xây dựng một mạng DL phức tạp. Để thuận tiện chúng ta sẽ dùng `nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feature = 5\n",
    "out_feature = 2\n",
    "\n",
    "input = torch.ones(6, 3, in_feature)\n",
    "\n",
    "linear = nn.Linear(in_feature, out_feature)\n",
    "\n",
    "output = linear(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Các module khác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bên cạnh Linear, pytorch còn đi kèm các layer khác. Các layer phổ biến là\n",
    "\n",
    "`nn.Conv1d`,\n",
    "`nn.Conv2d`,\n",
    "`nn.MaxPool2d`,\n",
    "`nn.Embedding`,\n",
    "`nn.LSTM`,\n",
    "`nn.LSTMCell`,\n",
    "`nn.MultiheadAttention`\n",
    "...\n",
    "và các activation `nn.Sigmoid`, `nn.Softmax`,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sigmoid()(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model  =nn.Sequential(\n",
    "    nn.Linear(in_feature, out_feature),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Custom module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể tự xây dựng các layers khác bằng cách extend từ `nn.Module`. Các bước bạn cần làm để tạp 1 custom module là:\n",
    "\n",
    "1. Khai báo các weight, layer cần dùng trong constructor\n",
    "2. Xây dựng lan truyền thuận trong hàm `forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, input_size:int, \n",
    "                 hidden_sizes: List[int], \n",
    "                 output_size: int):\n",
    "        # Call to the __init__ function of the super class\n",
    "        super(MyMLP, self).__init__()\n",
    "        layers = []\n",
    "        current_dim = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(current_dim, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_dim = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(current_dim, output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        out = F.softmax(x, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32\n",
    "hidden_sizes = [64, 64, 32]\n",
    "output_size = 5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((batch_size, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyMLP(input_size, hidden_sizes, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài tập 1: Sửa lỗi inference của model sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLPWide(nn.Module):\n",
    "    def __init__(self, input_size:int, \n",
    "                 hidden_sizes: List[int], \n",
    "                 output_size: int):\n",
    "        # Call to the __init__ function of the super class\n",
    "        super(MyMLPWide, self).__init__()\n",
    "        wide_layers = []\n",
    "        current_dim = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            wide_layers.append(nn.Linear(input_size, hidden_size))\n",
    "        \n",
    "        self.output_layer = nn.Linear(np.sum(hidden_sizes), output_size)\n",
    "        self.wide_layers = nn.ModuleList(wide_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for layer in self.wide_layers:\n",
    "            outputs.append(layer(x))\n",
    "        \n",
    "        outputs = torch.cat(outputs)\n",
    "        out = self.output_layer(outputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyMLPWide(input_size, hidden_sizes, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(inputs) Có shape bao nhiêu ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Optimizer & Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32\n",
    "hidden_sizes = [64, 64, 32]\n",
    "output_size = 1\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyMLPWide(input_size, hidden_sizes, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(batch_size, input_size)\n",
    "target = torch.ones(batch_size, 1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(inputs)\n",
    "    loss = loss_fn(y_pred, target)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demo Seq2Seq & Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1qzyPAt7YUVULEsOCIFUJ6DHgC58pgBYh?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.3 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.4 Seq2Seq & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.5 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Practice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Practice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tài liệu đọc thêm\n",
    "\n",
    "1. Autograd from scratch: [Grokking deeplearning - Chapter 13](https://livebook.manning.com/book/grokking-deep-learning/chapter-13?origin=product-toc)\n",
    "\n",
    "2. Official pytorch tutorial: [tutorials](https://pytorch.org/tutorials/)\n",
    "\n",
    "3. Deep learning with pytorch [book pdf](https://www.google.com/search?client=firefox-b-d&q=deep+learning+with+pytorch+book)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
